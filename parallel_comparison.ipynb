{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rgilyard/parallel-edge-detection/blob/main/parallel_comparison.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ab372b5-f2bd-40e6-859a-a107bbdc8973",
      "metadata": {
        "id": "6ab372b5-f2bd-40e6-859a-a107bbdc8973"
      },
      "source": [
        "# Edge Detection and Parallel Processing\n",
        "\n",
        "To Do List:\n",
        "- How to divide images into sections\n",
        "    Extending subblocks on those sides that neighbour other subblocks is a common pattern in parallel processing. It is called ghost cells pattern on halos pattern. https://stackoverflow.com/questions/11499872/dividing-large-image-for-parallel-processing Image segmentation\n",
        "- At the end of each run, save a .txt file with the file path and hyperperameters and results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d97f7c60-6bb6-40ea-a5c7-08e7b08d187e",
      "metadata": {
        "id": "d97f7c60-6bb6-40ea-a5c7-08e7b08d187e"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a7083cf-d0e4-4440-93d6-a3be452b46b8",
      "metadata": {
        "id": "1a7083cf-d0e4-4440-93d6-a3be452b46b8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from PIL import Image, ImageOps\n",
        "import os\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8c45206",
      "metadata": {
        "id": "d8c45206",
        "outputId": "b359c137-f2dd-4581-d651-2ffc82622e87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of available GPUs: 1\n"
          ]
        }
      ],
      "source": [
        "print(\"Number of available GPUs:\", torch.cuda.device_count())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3edd2fb2-ce2c-487c-863f-3fe39332c114",
      "metadata": {
        "id": "3edd2fb2-ce2c-487c-863f-3fe39332c114"
      },
      "source": [
        "### Check that CUDA is available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69b16dfc",
      "metadata": {
        "id": "69b16dfc",
        "outputId": "baab613e-32b0-4809-a1d4-d3b27f7e3704"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using cuda device\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")  # Use index 1 instead of the default index 0\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(\"using\", device, \"device\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ef5111f8-0fc3-4e7d-93a8-77a5ef835e5a",
      "metadata": {
        "id": "ef5111f8-0fc3-4e7d-93a8-77a5ef835e5a"
      },
      "source": [
        "## Set image folder paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86d183c5",
      "metadata": {
        "id": "86d183c5"
      },
      "outputs": [],
      "source": [
        "# Input and output paths\n",
        "image_folder = 'images'\n",
        "input_folder_path = 'input'\n",
        "output_folder_path = 'output'\n",
        "\n",
        "# Dummy path for multiple sequential loading\n",
        "dummy = 'dummy_class'\n",
        "single = 'single_images'\n",
        "\n",
        "# Multiple image paths\n",
        "img_16 = '16_images'\n",
        "img_64 = '64_images'\n",
        "img_256 = '256_images'\n",
        "img_1024 = '1024_images'\n",
        "img_4096 = '4096_images'\n",
        "multiple_image_paths = [img_16, img_64, img_256, img_1024, img_4096]\n",
        "\n",
        "# Single image paths\n",
        "x_small = 'pipe.png'\n",
        "small = 'cardsharps.png'\n",
        "med = 'washington.png'\n",
        "large = 'pedlar.jpg'\n",
        "x_large = 'pearl.png'\n",
        "single_image_paths = [x_small, small, med, large, x_large]\n",
        "\n",
        "# Lists for the algorithms to run, input then output paths\n",
        "# Should I do input and output as a tuple, and then the type of data as a title as a dict?\n",
        "# I'll do this better later\n",
        "multiple_sequential_paths = []\n",
        "multiple_parallel_paths = []\n",
        "single_sequential_paths = []\n",
        "single_parallel_paths = []\n",
        "\n",
        "# Make multiple image path lists\n",
        "for path in multiple_image_paths:\n",
        "#     print(image_folder)\n",
        "#     print(input_folder_path)\n",
        "#     print(dummy)\n",
        "#     print(path)\n",
        "    sequential = (os.path.join(image_folder, input_folder_path, path, dummy, ''), \\\n",
        "                  os.path.join(image_folder, output_folder_path, path, ''))\n",
        "    multiple_sequential_paths.append(sequential)\n",
        "    parallel = (os.path.join(image_folder, input_folder_path, path, ''), \\\n",
        "                  os.path.join(image_folder, output_folder_path, path, ''))\n",
        "    multiple_parallel_paths.append(parallel)\n",
        "                \n",
        "# Make single image path lists\n",
        "for path in single_image_paths:\n",
        "    sequential = (os.path.join(image_folder, input_folder_path, single, path), \\\n",
        "                  os.path.join(image_folder, output_folder_path, single, path))\n",
        "    single_sequential_paths.append(sequential)\n",
        "    parallel = (os.path.join(image_folder, input_folder_path, single, path), \\\n",
        "                  os.path.join(image_folder, output_folder_path, single, path))\n",
        "    single_parallel_paths.append(parallel)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17ad0d36",
      "metadata": {
        "id": "17ad0d36"
      },
      "source": [
        "## Set hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9bbd417",
      "metadata": {
        "id": "d9bbd417"
      },
      "outputs": [],
      "source": [
        "Image.MAX_IMAGE_PIXELS = 10_000_000_000\n",
        "\n",
        "batch_size = 2 # Number of image in a dataloader batch\n",
        "num_workers = 2 # Parallelization for dataloading (CPU, not GPU)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5039474a",
      "metadata": {
        "id": "5039474a"
      },
      "source": [
        "### Set constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b54ed3b",
      "metadata": {
        "id": "9b54ed3b"
      },
      "outputs": [],
      "source": [
        "# ADD CONSTANTS FOR PARALLEL AND SEQUENTIAL KERNELS, maybe define kernel separately\n",
        "\n",
        "# Sequential Sobel kernels\n",
        "sobel_x_kernel_seq = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=np.float32)\n",
        "sobel_y_kernel_seq = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=np.float32)\n",
        "\n",
        "# Sobel operator kernels for horizontal and vertical edges (parallel)\n",
        "sobel_x_kernel_par = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=torch.float32)\n",
        "sobel_y_kernel_par = torch.tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=torch.float32)\n",
        "\n",
        "# Unsqueeze the Sobel kernels to match the shape\n",
        "# (C_out, C_in, H_kernel, W_kernel)\n",
        "sobel_x_kernel_expanded = sobel_x_kernel_par.unsqueeze(0).unsqueeze(0).to(device)\n",
        "sobel_y_kernel_expanded = sobel_y_kernel_par.unsqueeze(0).unsqueeze(0).to(device)\n",
        "# sobel_y_kernel_expanded = sobel_y_kernel_par.unsqueeze(0).unsqueeze(0).to('cuda')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34a96c0d",
      "metadata": {
        "id": "34a96c0d"
      },
      "source": [
        "### Additional Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18b8151c",
      "metadata": {
        "id": "18b8151c"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms.functional as F\n",
        "\n",
        "# Function to save tensor to image\n",
        "def save_image_from_tensor(tensor_img, output_path):\n",
        "    # Convert the tensor back to a PIL image\n",
        "    pil_img = F.to_pil_image(tensor_img)\n",
        "    \n",
        "    # Save the image to the output folder\n",
        "    pil_img.save(output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e293214-38ed-41a8-bd4a-05f91c29d6ae",
      "metadata": {
        "id": "6e293214-38ed-41a8-bd4a-05f91c29d6ae"
      },
      "source": [
        "## Sequential Edge Detection Algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cd4e4ca",
      "metadata": {
        "id": "5cd4e4ca"
      },
      "source": [
        "#### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bfe76aa",
      "metadata": {
        "id": "3bfe76aa"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "from scipy import ndimage"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd02773b-a82e-42c4-b7f6-0004f2368104",
      "metadata": {
        "id": "cd02773b-a82e-42c4-b7f6-0004f2368104"
      },
      "source": [
        "### Sequential Single Image Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b04617da",
      "metadata": {
        "id": "b04617da"
      },
      "outputs": [],
      "source": [
        "# Edge detection for single image\n",
        "def sequential_single(file_path, output_folder):\n",
        "    # Load the image and convert it to grayscale\n",
        "    img = Image.open(file_path).convert(\"L\")\n",
        "\n",
        "    # Convert the image to a numpy array\n",
        "    img_array = np.asarray(img, dtype=np.float32)\n",
        "\n",
        "    # Apply Sobel kernels to the image\n",
        "    edge_x = ndimage.convolve(img_array, sobel_x_kernel_seq, mode=\"constant\", cval=0)\n",
        "    edge_y = ndimage.convolve(img_array, sobel_y_kernel_seq, mode=\"constant\", cval=0)\n",
        "\n",
        "    # Calculate the magnitude of the gradients\n",
        "    edge_magnitude = np.sqrt(edge_x ** 2 + edge_y ** 2)\n",
        "\n",
        "    # Normalize the edge magnitude to the range [0, 255]\n",
        "    edge_magnitude = edge_magnitude.astype(np.uint8)\n",
        "\n",
        "    # Create a PIL Image from the numpy array\n",
        "    edge_image = Image.fromarray(edge_magnitude)\n",
        "\n",
        "    # Save the edge-detected image to the output folder\n",
        "    edge_image.save(output_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9a972bf-af9a-4bdf-aab9-2e07fc2a8252",
      "metadata": {
        "id": "b9a972bf-af9a-4bdf-aab9-2e07fc2a8252"
      },
      "source": [
        "### Sequential Multiple Image Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bce519a",
      "metadata": {
        "id": "6bce519a"
      },
      "outputs": [],
      "source": [
        "# Sequential algorithm for all the images in a folder\n",
        "def sequential_multiple(input_folder, output_folder):\n",
        "    # Get the list of image file paths in the input folder\n",
        "    image_files = glob.glob(os.path.join(input_folder, \"*\"))\n",
        "\n",
        "    # Iterate through each image file\n",
        "    for index, file_path in enumerate(image_files):\n",
        "        # Load the image and convert it to grayscale\n",
        "        img = Image.open(file_path).convert(\"L\")\n",
        "\n",
        "        # Convert the image to a numpy array\n",
        "        img_array = np.asarray(img, dtype=np.float32)\n",
        "\n",
        "        # Apply Sobel kernels to the image\n",
        "        edge_x = ndimage.convolve(img_array, sobel_x_kernel_seq, mode=\"constant\", cval=0)\n",
        "        edge_y = ndimage.convolve(img_array, sobel_y_kernel_seq, mode=\"constant\", cval=0)\n",
        "\n",
        "        # Calculate the magnitude of the gradients\n",
        "        edge_magnitude = np.sqrt(edge_x ** 2 + edge_y ** 2)\n",
        "\n",
        "        # Normalize the edge magnitude to the range [0, 255]\n",
        "        edge_magnitude = edge_magnitude.astype(np.uint8)\n",
        "\n",
        "        # Create a PIL Image from the numpy array\n",
        "        edge_image = Image.fromarray(edge_magnitude)\n",
        "\n",
        "        # Save the edge-detected image to the output folder\n",
        "        file_name = os.path.basename(file_path)\n",
        "        img_output_path = os.path.join(output_folder, f'edge_{index}.png')\n",
        "        edge_image.save(img_output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5d1653b-d320-495e-b0f2-44ef9a26c541",
      "metadata": {
        "id": "a5d1653b-d320-495e-b0f2-44ef9a26c541"
      },
      "source": [
        "## Parallel Edge Detection Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "33e31263",
      "metadata": {
        "id": "33e31263"
      },
      "source": [
        "#### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7796ae2",
      "metadata": {
        "id": "d7796ae2"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.functional import conv2d\n",
        "import math\n",
        "from torchvision.transforms.functional import to_pil_image"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8fbb98fd",
      "metadata": {
        "id": "8fbb98fd"
      },
      "source": [
        "### Parallel Single Image Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2853391",
      "metadata": {
        "id": "b2853391"
      },
      "outputs": [],
      "source": [
        "def parallel_single(input_image_path, output_image_path, patch_size=256, overlap=2):\n",
        "    # Load the large image and convert it to grayscale\n",
        "    large_img = Image.open(input_image_path).convert(\"L\")\n",
        "    \n",
        "    width, height = large_img.size\n",
        "    # Calculate the number of patches required to cover the image\n",
        "    pad_width = (math.ceil((width - overlap) / (patch_size - overlap)) - 1) * (patch_size - overlap) + patch_size - width\n",
        "    pad_height = (math.ceil((height - overlap) / (patch_size - overlap)) - 1) * (patch_size - overlap) + patch_size - height\n",
        "\n",
        "    # Add padding to the image\n",
        "    large_img = ImageOps.expand(large_img, (0, 0, pad_width, pad_height), fill=0)\n",
        "    large_img.save(output_image_path)\n",
        "    \n",
        "    # New widtch and height\n",
        "    new_width, new_height = large_img.size\n",
        "\n",
        "    # Calculate the number of patches along width and height\n",
        "    # Come back and fix this so it isn't calculated twice\n",
        "    num_patches_w = math.ceil((new_width - overlap) / (patch_size - overlap))\n",
        "    num_patches_h = math.ceil((new_height - overlap) / (patch_size - overlap))\n",
        "\n",
        "    # Create an empty image to store the edge-detected result\n",
        "    output_img = Image.new(\"L\", (new_width, new_height))\n",
        "    \n",
        "    patches = []\n",
        "\n",
        "    for i in range(num_patches_h):\n",
        "        for j in range(num_patches_w):\n",
        "            # Extract a patch from the large image\n",
        "            left = j * (patch_size - overlap)\n",
        "            upper = i * (patch_size - overlap)\n",
        "            right = min(left + patch_size, new_width)\n",
        "            lower = min(upper + patch_size, new_height)\n",
        "            patch = large_img.crop((left, upper, right, lower))\n",
        "\n",
        "            # Convert the patch to a tensor\n",
        "            patch_tensor = transforms.ToTensor()(patch)\n",
        "            \n",
        "            # Append the patch tensor to the patches list\n",
        "            patches.append(patch_tensor)\n",
        "            \n",
        "    # Split the patches list into smaller sublists (batches)\n",
        "    patch_batches = [patches[i:i + batch_size] for i in range(0, len(patches), batch_size)]\n",
        "        \n",
        "    for batch_idx, patch_batch in enumerate(patch_batches):\n",
        "        # Stack the patch tensors together into a single tensor\n",
        "        patches_tensor = torch.stack(patch_batch).to(device)\n",
        "        \n",
        "        # Convolve the patches with the Sobel kernels\n",
        "        edge_x = conv2d(patches_tensor, sobel_x_kernel_expanded, padding=1)\n",
        "        edge_y = conv2d(patches_tensor, sobel_y_kernel_expanded, padding=1)\n",
        "\n",
        "        # Combine the horizontal and vertical edges using the L2 norm\n",
        "        edge_detected_patches = torch.sqrt(edge_x ** 2 + edge_y ** 2).squeeze()\n",
        "\n",
        "        # Process the edge-detected patches and paste them into the output image\n",
        "        for i, edge_detected_patch in enumerate(edge_detected_patches):\n",
        "            # I'M WONDERING IF I HAVE TO TRIM THE EDGE AND LOWER THE OVERLAP TO 1\n",
        "            # Convert the edge-detected patch back to a PIL image\n",
        "            edge_detected_patch = to_pil_image(edge_detected_patch.cpu())\n",
        "\n",
        "            # Calculate the index of the patch in the original patches list\n",
        "            original_patch_idx = batch_idx * batch_size + i\n",
        "\n",
        "            # Calculate the position of the patch in the output image\n",
        "            row_idx = original_patch_idx // num_patches_w\n",
        "            col_idx = original_patch_idx % num_patches_w\n",
        "            left = col_idx * (patch_size - overlap)\n",
        "            upper = row_idx * (patch_size - overlap)\n",
        "\n",
        "            # Paste the edge-detected patch into the output image\n",
        "            output_img.paste(edge_detected_patch, (left, upper))\n",
        "\n",
        "    # Save the edge-detected large image\n",
        "    output_img.save(output_image_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95419e6d-cb20-4b59-aa41-f7b548b0ac33",
      "metadata": {
        "id": "95419e6d-cb20-4b59-aa41-f7b548b0ac33"
      },
      "source": [
        "### Parallel Multiple Image Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eac18c94",
      "metadata": {
        "id": "eac18c94"
      },
      "outputs": [],
      "source": [
        "# Finds edges for all the images in a folder in parallel\n",
        "def parallel_multiple(img_folder, output_folder):\n",
        "    # Define the transformation pipeline (it's not much \n",
        "    # a pipline, because I'm only converting to tensors)\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Grayscale(num_output_channels=1),\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "    \n",
        "    # Create an ImageFolder dataset\n",
        "    dataset = ImageFolder(root=img_folder, transform=transform)\n",
        "    \n",
        "    # Create a DataLoader to handle batching\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
        "    \n",
        "    for batch_idx, (data, _) in enumerate(dataloader):\n",
        "        # Move the data to the GPU\n",
        "        data = data.to(device)\n",
        "        \n",
        "        # Convolve the image with the Sobel kernels\n",
        "        edge_x = conv2d(data, sobel_x_kernel_expanded, padding=1)\n",
        "        edge_y = conv2d(data, sobel_y_kernel_expanded, padding=1)\n",
        "\n",
        "        # Combine the horizontal and vertical edges using the L2 norm\n",
        "        edge_detected_batch = torch.sqrt(edge_x ** 2 + edge_y ** 2).squeeze()\n",
        "\n",
        "        # Save each image\n",
        "        for index, edge_detected_image in enumerate(edge_detected_batch):\n",
        "            img_output_path = os.path.join(output_folder, f'edge_{batch_idx * batch_size + index}.png')\n",
        "            save_image_from_tensor(edge_detected_image.cpu(), img_output_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "343d89b7-69b6-44c5-beba-0aae2ff25e22",
      "metadata": {
        "id": "343d89b7-69b6-44c5-beba-0aae2ff25e22"
      },
      "source": [
        "## Run Algorithms and Measure for Speed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c753ce7",
      "metadata": {
        "id": "7c753ce7"
      },
      "outputs": [],
      "source": [
        "import timeit\n",
        "\n",
        "# Function to time functions over all image paths\n",
        "# and return a list of times\n",
        "def time_function(function, paths):\n",
        "    print('timing functions')\n",
        "    time_list = []\n",
        "    for path in paths:\n",
        "        print('.')\n",
        "        # Record the start time\n",
        "        start_time = timeit.default_timer()\n",
        "        # Run the function\n",
        "        function(path[0], path[1])\n",
        "        # End timer, calculate time, append time to list\n",
        "        end_time = timeit.default_timer()\n",
        "        elapsed_time = end_time - start_time\n",
        "        time_list.append(elapsed_time)\n",
        "    print()\n",
        "    return time_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66727438",
      "metadata": {
        "scrolled": false,
        "id": "66727438",
        "outputId": "3890ee38-9bc5-4942-d007-93968695ebef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "timing functions\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n",
            ".\n"
          ]
        },
        {
          "ename": "MemoryError",
          "evalue": "Unable to allocate 13.4 GiB for an array with shape (65000, 55399) and data type float32",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[31], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# # List of multiple, sequential times\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# mult_seq_timings = time_function(sequential_multiple, multiple_sequential_paths)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      6\u001b[0m \n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# List of single, sequential times\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m sing_seq_timings \u001b[38;5;241m=\u001b[39m \u001b[43mtime_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequential_single\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msingle_sequential_paths\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# List of single, parallel times\u001b[39;00m\n\u001b[0;32m     11\u001b[0m sing_par_timings \u001b[38;5;241m=\u001b[39m time_function(parallel_single, single_parallel_paths)\n",
            "Cell \u001b[1;32mIn[30], line 13\u001b[0m, in \u001b[0;36mtime_function\u001b[1;34m(function, paths)\u001b[0m\n\u001b[0;32m     11\u001b[0m start_time \u001b[38;5;241m=\u001b[39m timeit\u001b[38;5;241m.\u001b[39mdefault_timer()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Run the function\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# End timer, calculate time, append time to list\u001b[39;00m\n\u001b[0;32m     15\u001b[0m end_time \u001b[38;5;241m=\u001b[39m timeit\u001b[38;5;241m.\u001b[39mdefault_timer()\n",
            "Cell \u001b[1;32mIn[25], line 7\u001b[0m, in \u001b[0;36msequential_single\u001b[1;34m(file_path, output_folder)\u001b[0m\n\u001b[0;32m      4\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(file_path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Convert the image to a numpy array\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m img_array \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Apply Sobel kernels to the image\u001b[39;00m\n\u001b[0;32m     10\u001b[0m edge_x \u001b[38;5;241m=\u001b[39m ndimage\u001b[38;5;241m.\u001b[39mconvolve(img_array, sobel_x_kernel_seq, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, cval\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
            "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 13.4 GiB for an array with shape (65000, 55399) and data type float32"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# # List of multiple, sequential times\n",
        "# mult_seq_timings = time_function(sequential_multiple, multiple_sequential_paths)\n",
        "\n",
        "# # List of multiple, parallel times\n",
        "# mult_par_timings = time_function(parallel_multiple, multiple_parallel_paths)\n",
        "\n",
        "# List of single, sequential times\n",
        "sing_seq_timings = time_function(sequential_single, single_sequential_paths)\n",
        "\n",
        "# List of single, parallel times\n",
        "sing_par_timings = time_function(parallel_single, single_parallel_paths)\n",
        "\n",
        "# # Run the sequential, multiple image algorithms\n",
        "# for path in multiple_sequential:\n",
        "#     # Record the start time\n",
        "#     start_time = timeit.default_timer()\n",
        "#     sequential_multiple(path[0], path[1])\n",
        "#     end_time = timeit.default_timer()\n",
        "#     elapsed_time = end_time - start_time\n",
        "#     timings.append(elapsed_time)\n",
        "\n",
        "    \n",
        "# # List of multiple, parallel times\n",
        "# mult_par_timings = []\n",
        "\n",
        "# for path in multiple_parallel:\n",
        "#     parallel_multiple(path[0], path[1])\n",
        "\n",
        "    \n",
        "# # List of single, sequential times\n",
        "# sing_seq_timings = []\n",
        "\n",
        "# for path in single_seuential:\n",
        "#     sequential_single(path[0], path[1])\n",
        "    \n",
        "    \n",
        "# # List of single, parallel times\n",
        "# sing_par_timings = []\n",
        "\n",
        "# for path in single_parallel:\n",
        "#     parallel_single(path[0], path[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00e614c7",
      "metadata": {
        "id": "00e614c7"
      },
      "outputs": [],
      "source": [
        "archive_times = [[8.805674300005194, 35.00109530001646, 136.28092169994488, 538.2281793999719, 2096.800743400003]\n",
        "                [7.89365889999317, 33.06302360002883, 128.1501998999738, 504.46940240002004, 1971.5305169000058]\n",
        "                [0.017573000048287213, 0.21468309999909252]\n",
        "                [0.16184509999584407, 0.3257216999772936]]\n",
        "\n",
        "print(mult_seq_timings)\n",
        "print(mult_par_timings)\n",
        "print(sing_seq_timings)\n",
        "print(sing_par_timings)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9003f270-7d3e-4425-9709-aeb823549e1d",
      "metadata": {
        "id": "9003f270-7d3e-4425-9709-aeb823549e1d"
      },
      "source": [
        "### Print Figures"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d622ffee-e601-4784-8752-5e7e38e44155",
      "metadata": {
        "id": "d622ffee-e601-4784-8752-5e7e38e44155"
      },
      "source": [
        "## Run Algorithms and Measure for Space"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db82b952-cc35-488f-a25f-539cd5ad9dac",
      "metadata": {
        "id": "db82b952-cc35-488f-a25f-539cd5ad9dac"
      },
      "source": [
        "### Print Figures"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}